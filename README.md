# Aves - Visual Spanish Bird Learning Platform

ğŸ¦… **An AI-powered inductive learning platform for Spanish ornithological vocabulary acquisition through interactive photography**

Aves leverages **visual-spatial memory**, **AI-powered annotations**, and **contextual discovery** to teach Spanish bird terminology through an engaging, image-based interface. Built with modern web technologies and following **SPARC methodology** for systematic feature development.

**ğŸš€ Live Demo**: [https://bjpl.github.io/aves/](https://bjpl.github.io/aves/) (GitHub Pages)

**ğŸ“Š Project Status**: Phase 3 Week 1 Complete - Production Ready
- âœ… **95%+ Backend Test Coverage** (production-ready)
- âœ… **67 Test Files** (264 frontend + 57 E2E + integration tests)
- âœ… **AI-Powered Features** (Vision AI annotations + GPT-4 exercises)
- âœ… **Deployed & Live** on GitHub Pages

## âœ¨ Core Features

### ğŸ¤– **AI-Powered Vision Annotations** (Phase 1)
- **GPT-4 Vision API** integration for automatic bird feature detection
- Intelligent annotation generation (anatomy, colors, behavior)
- Caching system to minimize API costs
- Batch processing for multiple images
- Automatic Spanish terminology mapping

### ğŸ¯ **Interactive Image Annotation System**
- Canvas-based high-performance rendering
- Interactive bounding box annotations
- Hover and click detection with coordinate mapping
- Support for anatomical, color, and behavioral annotations
- Responsive design with mobile support

### ğŸ“š **Progressive Vocabulary Disclosure**
- **5-level disclosure system**: Hidden â†’ Hover â†’ Click â†’ Etymology â†’ Examples
- Session-based progress tracking with React Query
- Visual feedback for discovered terms
- Contextual learning without cognitive overload
- Client-side state persistence with Zustand

### ğŸ® **AI-Powered Exercise Generation** (Phase 2)
- **GPT-4-based intelligent exercise creation**
- Multiple exercise types:
  - **Visual Discrimination**: Match images to Spanish terms
  - **Contextual Fill**: Complete sentences with correct vocabulary
  - **Term Matching**: Connect Spanish/English pairs
  - **Translation Practice**: Bidirectional translation
- Adaptive difficulty based on user performance
- Real-time feedback and progress tracking
- User context integration for personalized learning
- Exercise caching system (95%+ hit rate)

### ğŸ¦œ **Species Browser**
- Taxonomic hierarchy navigation (Order â†’ Family â†’ Genus â†’ Species)
- Multi-faceted filtering (habitat, size, color, behavior)
- Rich species profiles with distribution maps
- Conservation status indicators
- Client-side CMS for content management

### ğŸ“· **Image Sourcing Pipeline**
- Unsplash API integration with rate limiting
- Intelligent prompt generation for missing species
- Fallback image strategies
- Attribution and licensing compliance
- Sharp image processing and optimization

## ğŸ› ï¸ Technology Stack

### **Frontend Architecture**
- **React 18.2** with TypeScript 5.3 for type-safe component development
- **Vite 5.0** for lightning-fast HMR and optimized builds
- **TanStack React Query 5.90** for server state management
- **Zustand 4.4** for client-side state management
- **React Router v6.21** for declarative routing
- **Tailwind CSS 3.4** for utility-first styling
- **Canvas API** for performant annotation rendering
- **Axios 1.6** for HTTP requests
- **Lucide React** for icons
- **@annotorious/react 3.0** for advanced annotations

### **Backend Infrastructure**
- **Node.js 18+ + Express 4.18** REST API
- **PostgreSQL** via pg 8.11 with optimized indexing
- **OpenAI 4.20** for GPT-4 Vision and exercise generation
- **JWT + bcrypt** for authentication and security
- **Helmet 7.1** for HTTP security headers
- **express-rate-limit** for API protection
- **Zod 3.22** for runtime validation
- **Sharp 0.33** for image processing
- **Pino 9.13** for structured logging

### **Testing Infrastructure** (Phase 3 Week 1)
- **Vitest 1.1** for frontend unit/integration tests (264 tests)
- **Jest 29.7** for backend testing (95%+ coverage)
- **Playwright 1.55** for E2E testing (57 tests)
- **React Testing Library 14.3** for component tests
- **Supertest 7.1** for API endpoint testing
- **@vitest/coverage-v8** for code coverage reporting

### **Development Practices**
- **SPARC Methodology** for systematic feature development
- **TypeScript 5.3** throughout the stack
- **AI-Assisted Development** with Claude Code + Claude Flow
- **Barrel exports** for clean module organization
- **Git flow** with feature branches and semantic commits
- **Monorepo** architecture with npm workspaces
- **Comprehensive testing** (unit, integration, E2E)

## ğŸš€ Getting Started

### Prerequisites
- **Node.js 18+** and npm 9+
- **PostgreSQL 14+** (for backend development)
- **OpenAI API key** (for AI features - GPT-4 Vision and exercise generation)
- **Unsplash API key** (optional, for image sourcing)

### Installation

```bash
# Clone the repository
git clone https://github.com/bjpl/aves.git
cd aves

# Install all dependencies (uses npm workspaces)
npm install

# Set up environment variables for backend
cd backend
cp .env.example .env
# Edit backend/.env with your configuration (see below)

# Set up environment variables for frontend
cd ../frontend
cp .env.example .env
# Edit frontend/.env with your configuration (see below)

# Run database migrations (from backend directory)
cd ../backend
npm run migrate

# Start development servers (from project root)
cd ..
npm run dev
# Frontend runs on http://localhost:5173
# Backend runs on http://localhost:3001
```

### Environment Variables

**Backend** (`backend/.env`):
```env
# Server Configuration
NODE_ENV=development
PORT=3001

# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=aves
DB_USER=postgres
DB_PASSWORD=your_password
DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}

# OpenAI Configuration (Required for AI features)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=1500

# External APIs (Optional)
UNSPLASH_ACCESS_KEY=your_unsplash_key

# Security
SESSION_SECRET=your_session_secret_change_in_production
JWT_SECRET=your_jwt_secret_change_in_production

# CORS Configuration
FRONTEND_URL=http://localhost:5173

# Feature Flags
ENABLE_VISION_AI=true
ENABLE_EXERCISE_GENERATION=true
ENABLE_BATCH_PROCESSING=true
```

**Frontend** (`frontend/.env`):
```env
# API Configuration
VITE_API_URL=http://localhost:3001
VITE_API_VERSION=v1

# Feature Flags
VITE_ENABLE_UNSPLASH=true
VITE_ENABLE_AI_EXERCISES=true
VITE_ENABLE_VISION_AI=true
VITE_DEBUG_MODE=true
```

## ğŸ“ Project Structure

```
aves/
â”œâ”€â”€ frontend/                       # React application (Vite + TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/            # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ annotations/       # Canvas annotation system
â”‚   â”‚   â”‚   â”œâ”€â”€ exercises/         # AI exercise components
â”‚   â”‚   â”‚   â”œâ”€â”€ learn/             # Learning interface
â”‚   â”‚   â”‚   â”œâ”€â”€ practice/          # Practice mode
â”‚   â”‚   â”‚   â””â”€â”€ ui/                # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/                 # Route-level page components
â”‚   â”‚   â”œâ”€â”€ hooks/                 # Custom React hooks (12 hooks)
â”‚   â”‚   â”œâ”€â”€ services/              # API clients and services
â”‚   â”‚   â”‚   â”œâ”€â”€ aiExerciseService.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ exerciseGenerator.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ unsplashService.ts
â”‚   â”‚   â”‚   â””â”€â”€ clientDataService.ts
â”‚   â”‚   â”œâ”€â”€ utils/                 # Helper functions
â”‚   â”‚   â”œâ”€â”€ types/                 # TypeScript type definitions
â”‚   â”‚   â”œâ”€â”€ constants/             # App-wide constants
â”‚   â”‚   â”œâ”€â”€ __tests__/             # Test files (264 tests)
â”‚   â”‚   â””â”€â”€ test/                  # Test utilities
â”‚   â”œâ”€â”€ e2e/                       # Playwright E2E tests (57 tests)
â”‚   â””â”€â”€ public/                    # Static assets
â”œâ”€â”€ backend/                        # Express API server
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/                # API endpoints (REST)
â”‚   â”‚   â”‚   â”œâ”€â”€ aiAnnotations.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ aiExercises.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ exercises.ts
â”‚   â”‚   â”‚   â””â”€â”€ auth.ts
â”‚   â”‚   â”œâ”€â”€ services/              # Business logic layer
â”‚   â”‚   â”‚   â”œâ”€â”€ VisionAI.ts        # GPT-4 Vision integration
â”‚   â”‚   â”‚   â”œâ”€â”€ aiExerciseGenerator.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ ExerciseService.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ UserService.ts
â”‚   â”‚   â”‚   â””â”€â”€ exerciseCache.ts
â”‚   â”‚   â”œâ”€â”€ middleware/            # Express middleware
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ adminAuth.ts
â”‚   â”‚   â”‚   â””â”€â”€ validate.ts
â”‚   â”‚   â”œâ”€â”€ database/              # Database utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ connection.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ migrate.ts
â”‚   â”‚   â”‚   â””â”€â”€ migrations/        # SQL migration files
â”‚   â”‚   â”œâ”€â”€ models/                # Data models
â”‚   â”‚   â”œâ”€â”€ prompts/               # AI prompt templates
â”‚   â”‚   â”œâ”€â”€ validation/            # Zod schemas
â”‚   â”‚   â””â”€â”€ __tests__/             # Jest tests (95%+ coverage)
â”‚   â””â”€â”€ coverage/                  # Test coverage reports
â”œâ”€â”€ shared/                         # Shared TypeScript types
â”‚   â””â”€â”€ types/                     # Common type definitions
â”œâ”€â”€ database/                       # Database schema files
â”‚   â””â”€â”€ schemas/                   # SQL schema definitions
â”œâ”€â”€ docs/                           # Comprehensive documentation (53+ files)
â”‚   â”œâ”€â”€ AI_IMPLEMENTATION_PLAN.md
â”‚   â”œâ”€â”€ EXERCISE_GENERATION_GUIDE.md
â”‚   â”œâ”€â”€ PHASE_2_COMPLETION_REPORT.md
â”‚   â”œâ”€â”€ PROJECT_STATUS_REPORT.md
â”‚   â”œâ”€â”€ api/                       # API documentation
â”‚   â”œâ”€â”€ examples/                  # Code examples
â”‚   â”œâ”€â”€ testing/                   # Testing documentation
â”‚   â””â”€â”€ database/                  # Database documentation
â”œâ”€â”€ .claude/                        # Claude Code configuration
â”œâ”€â”€ .claude-flow/                   # Claude Flow swarm configuration
â”œâ”€â”€ .swarm/                         # Swarm coordination data
â”œâ”€â”€ api/                            # API documentation assets
â”œâ”€â”€ cms/                            # Content management data
â”œâ”€â”€ data/                           # Application data files
â””â”€â”€ memory/                         # Development session memory
```

## ğŸ”§ Development

### Available Scripts

**Root workspace scripts:**
```bash
npm run dev              # Run both frontend + backend concurrently
npm run dev:frontend     # Start frontend dev server (Vite on :5173)
npm run dev:backend      # Start backend dev server (Express on :3001)
npm run build            # Build both frontend + backend
npm run test             # Run tests in both workspaces
npm run lint             # Lint both workspaces
```

**Frontend scripts** (`cd frontend`):
```bash
npm run dev              # Start Vite dev server
npm run build            # Build for production
npm run build:gh-pages   # Build for GitHub Pages deployment
npm run preview          # Preview production build
npm run preview:gh-pages # Preview GitHub Pages build
npm run deploy           # Deploy to GitHub Pages
npm run test             # Run Vitest unit tests
npm run test:e2e         # Run Playwright E2E tests
npm run test:e2e:ui      # Run E2E tests with UI
npm run test:e2e:headed  # Run E2E tests in headed mode
npm run test:e2e:debug   # Debug E2E tests
npm run test:e2e:smoke   # Run smoke tests only
npm run test:e2e:report  # Show Playwright test report
npm run lint             # Run ESLint
```

**Backend scripts** (`cd backend`):
```bash
npm run dev              # Start server with tsx watch (hot reload)
npm run build            # Compile TypeScript to dist/
npm run start            # Start production server from dist/
npm run test             # Run Jest tests
npm run lint             # Run ESLint
npm run migrate          # Run database migrations
npm run validate-config  # Validate environment configuration
```

**Testing commands:**
```bash
# Frontend tests
cd frontend && npm run test                # Vitest unit tests
cd frontend && npm run test:e2e            # Playwright E2E tests

# Backend tests (95%+ coverage)
cd backend && npm run test                 # Jest with coverage

# All tests
npm run test                               # Run all workspace tests
```

### API Documentation

The API follows RESTful conventions. Full documentation available in [`docs/api/`](docs/api/) and [`docs/AI_EXERCISE_GENERATION_API.md`](docs/AI_EXERCISE_GENERATION_API.md).

#### Key Endpoints

**AI-Powered Endpoints** (Phase 1 & 2):
```typescript
// AI Vision Annotations
POST   /api/ai/annotations/generate      // Generate annotations with GPT-4 Vision
POST   /api/ai/annotations/batch         // Batch process multiple images
GET    /api/ai/annotations/:speciesId    // Get AI-generated annotations

// AI Exercise Generation
POST   /api/ai/exercises/generate        // Generate exercises with GPT-4
POST   /api/ai/exercises/generate/batch  // Batch generate exercises
GET    /api/ai/exercises/cached          // Get cached exercises
POST   /api/ai/exercises/invalidate      // Invalidate exercise cache

// User Context Building
GET    /api/users/:userId/context        // Get user learning context
POST   /api/users/:userId/progress       // Update user progress
```

**Core Endpoints**:
```typescript
// Annotations
GET    /api/annotations                  // List all annotations
POST   /api/annotations                  // Create new annotation
GET    /api/annotations/:id              // Get specific annotation
PUT    /api/annotations/:id              // Update annotation
DELETE /api/annotations/:id              // Delete annotation

// Vocabulary
GET    /api/vocabulary/progress          // Get user progress
POST   /api/vocabulary/interact          // Record interaction
GET    /api/vocabulary/terms             // List vocabulary terms

// Exercises
POST   /api/exercises/session/start      // Start exercise session
POST   /api/exercises/result             // Submit exercise result
GET    /api/exercises/session/:id/progress  // Get session progress
GET    /api/exercises/difficult-terms    // Get difficult terms analysis

// Authentication
POST   /api/auth/register                // Register new user
POST   /api/auth/login                   // User login
POST   /api/auth/logout                  // User logout
GET    /api/auth/verify                  // Verify JWT token

// Images
GET    /api/images/search                // Search Unsplash
GET    /api/images/:id                   // Get image details
POST   /api/images/cache                 // Cache image locally
```

## ğŸ¯ SPARC Methodology

Each feature undergoes a complete SPARC cycle:

### **S**pecification
Define clear requirements, constraints, and success criteria

### **P**seudocode
Design algorithms and logic flow before implementation

### **A**rchitecture
Plan technical design, component structure, and data flow

### **R**efinement
Optimize performance, enhance UX, and address edge cases

### **C**ompletion
Ensure testing coverage, documentation, and deployment readiness

## ğŸ“Š Learning Principles

### **Inductive Learning Approach**
- Discovery-based rather than instruction-based
- Visual context precedes linguistic labels
- Progressive complexity from concrete to abstract

### **Cognitive Load Management**
- Chunked information presentation
- Just-in-time vocabulary disclosure
- Spaced practice opportunities

### **Multi-Modal Reinforcement**
- Visual (images and annotations)
- Textual (Spanish and English terms)
- Interactive (exercises and exploration)
- Contextual (sentences and usage examples)

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guide](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

### Development Workflow
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Follow SPARC methodology for new features
4. Commit changes (`git commit -m 'Add AmazingFeature'`)
5. Push to branch (`git push origin feature/AmazingFeature`)
6. Open a Pull Request

## ğŸ“ˆ Roadmap

### âœ… Completed Phases

**Phase 1: Vision AI & Annotation System** (Completed)
- âœ… GPT-4 Vision integration for automatic bird feature detection
- âœ… Canvas-based interactive annotation system
- âœ… Caching and batch processing
- âœ… Responsive design with mobile support

**Phase 2: Intelligent Exercise Generation** (Completed)
- âœ… GPT-4-powered exercise generation
- âœ… Multiple exercise types (visual discrimination, contextual fill, term matching)
- âœ… User context integration for personalized learning
- âœ… Exercise caching system (95%+ hit rate)
- âœ… Session-based progress tracking

**Phase 3 Week 1: Testing & Quality Assurance** (Completed)
- âœ… Backend test coverage: 95%+
- âœ… Frontend tests: 264 tests with Vitest
- âœ… E2E tests: 57 Playwright tests
- âœ… Integration tests: 5 critical workflow tests
- âœ… Comprehensive documentation (53+ files)

### ğŸš§ In Progress

**Phase 3 Week 2-5: Production Readiness**
- [ ] DevOps & Infrastructure (Docker, CI/CD)
- [ ] Performance optimization (code splitting, lazy loading)
- [ ] Security hardening (penetration testing, security audit)
- [ ] Accessibility improvements (WCAG 2.1 AA compliance)

### ğŸ”® Future Enhancements

**Phase 4: Advanced Features**
- [ ] Audio pronunciations for Spanish terms
- [ ] Social features (leaderboards, progress sharing)
- [ ] Spaced repetition algorithm (SRS)
- [ ] Offline mode with service workers
- [ ] Real-time multiplayer exercises

**Phase 5: Platform Expansion**
- [ ] Multi-language support (French, German, Italian)
- [ ] Mobile native apps (React Native)
- [ ] AR bird identification mode (camera integration)
- [ ] Public API for third-party integrations
- [ ] White-label solution for educators

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **OpenAI** for GPT-4 Vision and GPT-4 Turbo APIs powering AI features
- **Anthropic** for Claude Code and Claude Flow enabling AI-assisted development
- **Unsplash** for providing high-quality bird photography
- **Cornell Lab of Ornithology** for taxonomic data and bird information
- **SPARC Methodology** for structured development approach
- **Open source community** for the amazing tools and libraries
  - React, TypeScript, Vite, Playwright, Vitest, Jest, and many more

## ğŸ¤– AI-Assisted Development

This project leverages **AI-assisted development** with:
- **Claude Code** for intelligent code generation and refactoring
- **Claude Flow** for swarm-based parallel development (2.8-4.4x speed improvement)
- **SPARC methodology** integrated with AI workflows
- **GPT-4** for exercise generation and vision annotations

**Development Velocity**: 270% test increase in Phase 3 Week 1 through AI assistance.

---

**Built with ğŸ§¡ for language learners and bird enthusiasts**

**ğŸš€ [Live Demo](https://bjpl.github.io/aves/)** | [Documentation](docs/) | [Report Issues](https://github.com/bjpl/aves/issues) | [Phase 2 Guide](README_PHASE2.md)